import sys
import os
from pathlib import Path

PROJECT_FILES = {
    "app.py": '''from fastapi import FastAPI, Request, Body\nfrom fastmcp import Client\nfrom fastmcp.client.transports import StreamableHttpTransport, StdioTransport\nfrom fastapi.templating import Jinja2Templates\nfrom fastapi.responses import HTMLResponse\nimport os\nimport openai\nimport subprocess\nimport signal\nimport logging\nfrom fastapi import status\n\napp = FastAPI()\n\n# Configuration\nNANOBOT_MCP_URL = os.environ.get("NANOBOT_MCP_URL", "http://localhost:8099/mcp")\nOPENAI_MODEL = os.environ.get("OPENAI_MODEL", "gpt-4.1")\nOPENAI_API_KEY = os.environ.get("OPENAI_API_KEY", "")\nopenai.api_key = OPENAI_API_KEY\n\nmcp_client = Client(StreamableHttpTransport(url=NANOBOT_MCP_URL))\nprompt_mcp_client = Client(StdioTransport(command="uv", args=["run", "prompts.py"]))\ntemplates = Jinja2Templates(directory="templates")\n\nnanobot_process = None\n\n@app.on_event("startup")\ndef start_nanobot():\n    global nanobot_process\n    import nanobot_template_util\n    nanobot_template_util.merge_all_configs()\n    if nanobot_process is None:\n        nanobot_process = subprocess.Popen([\n            "nanobot", "run", ".", "--listen-address", "127.0.0.1:8099"\n        ])\n\n@app.on_event("shutdown")\ndef stop_nanobot():\n    global nanobot_process\n    if nanobot_process is not None:\n        nanobot_process.send_signal(signal.SIGINT)\n        nanobot_process.wait()\n        nanobot_process = None\n\n@app.get("/", response_class=HTMLResponse)\nasync def chat_view(request: Request):\n    chat_response = request.query_params.get("chat_response")\n    try:\n        async with mcp_client:\n            tools = await mcp_client.list_tools()\n        prompts = []\n        try:\n            async with prompt_mcp_client:\n                prompt_objs = await prompt_mcp_client.list_prompts()\n                prompts = [\n                    {\n                        "name": p.name,\n                        "description": getattr(p, "description", ""),\n                        "arguments": [\n                            {\n                                "name": a.name,\n                                "description": getattr(a, "description", ""),\n                                "required": getattr(a, "required", False)\n                            } for a in getattr(p, "arguments", [])\n                        ]\n                    } for p in prompt_objs\n                ]\n        except Exception as e:\n            print(f"[WARN] Could not fetch prompts: {e}")\n        return templates.TemplateResponse(\n            "base.html",\n            {\n                "request": request,\n                "message": "Welcome to nano-rails!",\n                "openai_model": OPENAI_MODEL,\n                "tools": [tool.name for tool in tools],\n                "prompts": prompts,\n                "error": None,\n                "chat_response": chat_response,\n            }\n        )\n    except Exception as e:\n        logging.exception("Failed to connect to MCP server or list tools")\n        return templates.TemplateResponse(\n            "base.html",\n            {\n                "request": request,\n                "message": "Could not connect to MCP server or list tools.",\n                "openai_model": OPENAI_MODEL,\n                "tools": [],\n                "prompts": [],\n                "error": str(e),\n                "chat_response": chat_response,\n            },\n            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR\n        )\n''',
    "prompts.py": '''from fastmcp import FastMCP\nimport importlib.util\nimport sys\nfrom pathlib import Path\n\nmcp = FastMCP(name="prompts")\n\nAGENTS_DIR = Path(__file__).parent / "agents"\n\nfor agent_dir in AGENTS_DIR.iterdir():\n    prompt_path = agent_dir / "prompt.py"\n    if prompt_path.exists():\n        spec = importlib.util.spec_from_file_location(f"{agent_dir.name}_prompt", str(prompt_path))\n        module = importlib.util.module_from_spec(spec)\n        sys.modules[spec.name] = module\n        spec.loader.exec_module(module)\n        if hasattr(module, "register_prompts"):\n            module.register_prompts(mcp)\n\nif __name__ == "__main__":\n    mcp.run()\n''',
    "nanobot_template_util.py": '''import os\nimport yaml\nfrom pathlib import Path\n\nROOT = Path(__file__).parent\nAGENTS_DIR = ROOT / "agents"\nGLOBAL_YAML = ROOT / "nanobot_global.yaml"\nOUTPUT_YAML = ROOT / "nanobot.yaml"\n\ndef load_yaml(path):\n    with open(path, "r") as f:\n        return yaml.safe_load(f)\n\ndef adjust_mcp_paths(agent_name, mcp_servers):\n    for server in mcp_servers.values():\n        if not server:\n            continue\n        if "args" in server:\n            new_args = []\n            for arg in server["args"]:\n                if arg.endswith(".py"):\n                    new_args.append(str(AGENTS_DIR / agent_name / arg))\n                else:\n                    new_args.append(arg)\n            server["args"] = new_args\n    return mcp_servers\n\ndef merge_nanobot_yamls():\n    merged = {"publish": {"tools": []}, "agents": {}, "mcpServers": {}}\n    if GLOBAL_YAML.exists():\n        global_yaml = load_yaml(GLOBAL_YAML)\n        for k in ["publish", "agents", "mcpServers"]:\n            if k in global_yaml:\n                if isinstance(global_yaml[k], dict):\n                    merged[k].update(global_yaml[k])\n                elif isinstance(global_yaml[k], list):\n                    merged[k]["tools"].extend(global_yaml[k])\n    for agent_dir in AGENTS_DIR.iterdir():\n        if not agent_dir.is_dir():\n            continue\n        agent_yaml_path = agent_dir / "nanobot.yaml"\n        if not agent_yaml_path.exists():\n            continue\n        agent_yaml = load_yaml(agent_yaml_path)\n        if "publish" in agent_yaml and "tools" in agent_yaml["publish"]:\n            merged["publish"]["tools"].extend(agent_yaml["publish"]["tools"])\n        if "agents" in agent_yaml:\n            merged["agents"].update(agent_yaml["agents"])\n        if "mcpServers" in agent_yaml:\n            adj = adjust_mcp_paths(agent_dir.name, agent_yaml["mcpServers"])\n            for k, v in adj.items():\n                if v is not None and isinstance(v, dict):\n                    merged["mcpServers"][k] = v\n    merged["publish"]["tools"] = list(sorted(set(merged["publish"]["tools"])))\n    with open(OUTPUT_YAML, "w") as f:\n        f.write("# DO NOT EDIT: This file is autogenerated by nanobot_template_util.py.\n")\n        yaml.dump(merged, f, sort_keys=False)\n    print(f"Merged nanobot.yaml written to {OUTPUT_YAML}")\n\ndef merge_all_configs():\n    return merge_nanobot_yamls()\n\nif __name__ == "__main__":\n    merge_nanobot_yamls()\n''',
    "pyproject.toml": '''[project]\nname = "nano-rails"\nversion = "0.1.0"\ndescription = "Add your description here"\nreadme = "README.md"\nrequires-python = ">=3.13"\ndependencies = [\n    "fastapi>=0.115.12",\n    "fastmcp>=2.3.5",\n    "jinja2>=3.1.6",\n    "openai>=1.79.0",\n    "pyyaml>=6.0.2",\n]\n\n[project.scripts]\ncreate_agent = "tread_manage:create_agent"\ncreate_project = "tread_manage:create_project"\n''',
    "README.md": """# nano-rails\n\nA Python framework for building LLM applications with MCP and OpenAI, inspired by Rails/Django.\n\n## Quickstart\n\n1. Install dependencies:\n\n```zsh\npip install fastapi fastmcp uvicorn\n```\n\n2. Set environment variables as needed:\n\n```zsh\nexport NANOBOT_MCP_URL=\"http://localhost:8099/mcp\"\nexport OPENAI_MODEL=\"gpt-4o\"\nexport OPENAI_API_KEY=\"sk-...\"\n```\n\n3. Run the server:\n\n```zsh\nuvicorn app:app --reload\n```\n\n4. Open [http://localhost:8000/](http://localhost:8000/) to see the default chat/tools view.\n""",
    "templates/base.html": '''<!DOCTYPE html>\n<html lang=\"en\">\n<head>\n    <meta charset=\"UTF-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n    <title>nano-rails</title>\n    <link rel=\"stylesheet\" href=\"https://cdn.jsdelivr.net/npm/@picocss/pico@2.0.6/css/pico.min.css\">\n</head>\n<body>\n    <main class=\"container\">\n        <header>\n            <h1>nano-rails</h1>\n            <p class=\"secondary\">A Python framework for LLM apps with MCP & OpenAI</p>\n        </header>\n        {% if error %}\n        <article style=\"background:#fee; color:#900; border:1px solid #c00; padding:1em;\">\n            <strong>Error:</strong> {{ error }}\n        </article>\n        {% endif %}\n        <section>\n            <h2>Chat with {{ openai_model }}</h2>\n            <form id=\"chat-form\" method=\"post\" action=\"/chat\" onsubmit=\"return sendChat(event)\">\n                <input type=\"text\" name=\"prompt\" id=\"prompt\" placeholder=\"Say something...\" required style=\"width:80%\">\n                <button type=\"submit\">Send</button>\n            </form>\n            <div id=\"chat-response\" style=\"margin-top:1em; font-size:1.1em; color:#333;\">\n                {% if chat_response %}\n                    <strong>Model:</strong> <span id=\"chat-markdown\">{{ chat_response|safe }}</span>\n                {% endif %}\n            </div>\n        </section>\n        <section>\n            <h2>Available Tools</h2>\n            <ul>\n            {% for tool in tools %}\n                <li>{{ tool }}</li>\n            {% else %}\n                <li><em>No tools found.</em></li>\n            {% endfor %}\n            </ul>\n        </section>\n        <section>\n            <h2>Available Prompts</h2>\n            <ul>\n            {% for prompt in prompts %}\n                <li style=\"margin-bottom:1em;\">\n                    <form class=\"prompt-form\" onsubmit=\"return callPrompt(event, '{{ prompt.name }}')\">\n                        <strong>{{ prompt.name }}</strong>\n                        {% if prompt.description %}<br><small>{{ prompt.description }}</small>{% endif %}\n                        {% for arg in prompt.arguments %}\n                            <input type=\"text\" name=\"{{ arg.name }}\" placeholder=\"{{ arg.name }}\" {% if arg.required %}required{% endif %} style=\"margin:0.25em;\">\n                        {% endfor %}\n                        <button type=\"submit\">Run</button>\n                    </form>\n                </li>\n            {% else %}\n                <li><em>No prompts found.</em></li>\n            {% endfor %}\n            </ul>\n        </section>\n    </main>\n    <script src=\"https://cdn.jsdelivr.net/npm/marked/marked.min.js\"></script>\n    <script>\n    async function sendChat(event) {\n        event.preventDefault();\n        const prompt = document.getElementById('prompt').value;\n        const respDiv = document.getElementById('chat-response');\n        respDiv.innerHTML = '<em>Loading...</em>';\n        const res = await fetch('/chat', {\n            method: 'POST',\n            headers: { 'Content-Type': 'application/json' },\n            body: JSON.stringify({ prompt })\n        });\n        const data = await res.json();\n        respDiv.innerHTML = `<strong>Model:</strong> <span id=\"chat-markdown\"></span>`;\n        document.getElementById('chat-markdown').innerHTML = marked.parse(data.response || '');\n        document.getElementById('prompt').value = '';\n        return false;\n    }\n    async function callPrompt(event, promptName) {\n        event.preventDefault();\n        const form = event.target;\n        const args = {};\n        form.querySelectorAll('input').forEach(i => args[i.name] = i.value.trim());\n        const respDiv = document.getElementById('chat-response');\n        respDiv.innerHTML = '<em>Loading prompt...</em>';\n        const res = await fetch('/prompt_call', {\n            method: 'POST',\n            headers: { 'Content-Type': 'application/json' },\n            body: JSON.stringify({ name: promptName, arguments: args })\n        });\n        const data = await res.json();\n        if (data.text) {\n            document.getElementById('prompt').value = data.text;\n            document.getElementById('prompt').focus();\n            respDiv.innerHTML = '<em>Prompt loaded into chat box. Edit or send!</em>';\n        } else {\n            respDiv.innerHTML = `<span style='color:red;'>Prompt error: ${data.error || 'Unknown error'}</span>`;\n        }\n        return false;\n    }\n    window.addEventListener('DOMContentLoaded', () => {\n        const chatSpan = document.getElementById('chat-markdown');\n        if (chatSpan && chatSpan.textContent) {\n            chatSpan.innerHTML = marked.parse(chatSpan.textContent);\n        }\n    });\n    </script>\n</body>\n</html>\n''',
    "nanobot_global.yaml": '''publish: 
  tools: [nanobot]

agents:
  nanobot:
    model: gpt-4.1
    description: "Call this to talk to nanobot."
    instructions: |-
      You are a friendly Nanobot assistant who answers questions.
''',
}


def create_project():
    if len(sys.argv) < 2:
        print("Usage: create_project [PROJECT_NAME]")
        sys.exit(1)
    project = sys.argv[1]
    root = Path(project)
    (root / "agents").mkdir(parents=True, exist_ok=True)
    (root / "templates").mkdir(parents=True, exist_ok=True)
    for fname, content in PROJECT_FILES.items():
        fpath = root / fname
        fpath.parent.mkdir(parents=True, exist_ok=True)
        with open(fpath, "w") as f:
            f.write(content)
    print(f"nano-rails project '{project}' scaffolded.")

# ...existing code for create_agent (moved from create_agent.py) ...
import sys
AGENTS_DIR = Path(__file__).parent / "agents"
NANOBOT_YAML_TEMPLATE = """publish:\n  tools: [{{name}}]\n\nagents:\n  {{name}}:\n    model: gpt-4.1\n    instructions: |-\n      You are a {{name}} agent. Describe what you do here.\n    tools: [{{name}}_tools]\n\nmcpServers:\n  {{name}}_tools:\n    command: \"uv\"\n    args:\n    - \"run\"\n    - \"tools.py\"\n"""
TOOLS_PY_TEMPLATE = """from fastmcp import FastMCP\n\nmcp = FastMCP(name=\"{{name}}\")\n\n@mcp.tool()\ndef {{name}}(text: str) -> str:\n    '''Describe what this tool does.'''\n    return f\"{{name}} tool called with: {{text}} (stub)\"\n\nif __name__ == \"__main__\":\n    mcp.run()\n"""
PROMPT_PY_TEMPLATE = """from fastmcp import FastMCP\n\ndef register_prompts(mcp: FastMCP):\n    @mcp.prompt()\n    def {{name}}_prompt(text: str) -> str:\n        '''Describe what this prompt does.'''\n        return f\"Prompt for {{name}}: {{text}} (stub)\"\n"""
def create_agent():
    if len(sys.argv) < 2:
        print("Usage: create_agent [AGENT_NAME]")
        sys.exit(1)
    agent = sys.argv[1]
    agent_dir = AGENTS_DIR / agent
    agent_dir.mkdir(parents=True, exist_ok=True)
    with open(agent_dir / "nanobot.yaml", "w") as f:
        f.write(NANOBOT_YAML_TEMPLATE.format(name=agent))
    with open(agent_dir / "tools.py", "w") as f:
        f.write(TOOLS_PY_TEMPLATE.format(name=agent))
    with open(agent_dir / "prompt.py", "w") as f:
        f.write(PROMPT_PY_TEMPLATE.format(name=agent))
    print(f"Agent '{agent}' created in {agent_dir}")

if __name__ == "__main__":
    if len(sys.argv) > 1 and sys.argv[1] == "create_project":
        sys.argv.pop(1)
        create_project()
    elif len(sys.argv) > 1 and sys.argv[1] == "create_agent":
        sys.argv.pop(1)
        create_agent()
    else:
        print("Usage: tread_manage.py [create_project|create_agent] [NAME]")
        sys.exit(1)
